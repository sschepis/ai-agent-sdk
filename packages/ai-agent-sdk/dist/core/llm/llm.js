"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.LLM = void 0;
const base_1 = require("../base");
const anthropic_1 = require("@ai-sdk/anthropic");
const google_1 = require("@ai-sdk/google");
const openai_1 = require("@ai-sdk/openai");
const ai_1 = require("ai");
class LLM extends base_1.Base {
    model;
    constructor({ provider, id }) {
        super("llm");
        switch (provider) {
            case "openai":
                this.model = (0, openai_1.openai)(id);
                break;
            case "deepseek":
                const deepseekProvider = (0, openai_1.createOpenAI)({
                    baseURL: "https://api.deepseek.ai/v1",
                });
                this.model = deepseekProvider(id);
                break;
            case "anthropic":
                this.model = (0, anthropic_1.anthropic)(id);
                break;
            case "google":
                this.model = (0, google_1.google)(id);
                break;
        }
    }
    async generate(args, viaAgent = false) {
        try {
            const hasTools = "tools" in args && Object.keys(args.tools ?? {}).length > 0;
            const isTextResponse = viaAgent || hasTools;
            if (isTextResponse) {
                const { tools, ...textArgs } = args;
                const response = await (0, ai_1.generateText)({
                    model: this.model,
                    toolChoice: "auto",
                    maxSteps: 3,
                    maxRetries: 5,
                    tools: tools,
                    ...textArgs,
                });
                if (!response.text) {
                    throw new Error("No response text generated by the model. Consider increasing `maxSteps` and/or `maxRetries`");
                }
                return {
                    type: "assistant",
                    value: response.text,
                };
            }
            else {
                const objectArgs = args;
                const response = await (0, ai_1.generateObject)({
                    model: this.model,
                    maxRetries: 5,
                    output: "object",
                    ...objectArgs,
                });
                if (!response.object) {
                    throw new Error("No response object");
                }
                return {
                    type: "assistant",
                    value: response.object,
                };
            }
        }
        catch (error) {
            throw new Error(`Failed to parse response: ${error}`);
        }
    }
}
exports.LLM = LLM;
//# sourceMappingURL=llm.js.map