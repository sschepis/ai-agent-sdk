import { Base } from "../base";
import type {
    GenerateObjectParams,
    GenerateTextParams,
    LLMParameters,
    LLMResponse,
    LLMStructuredResponse,
    LLMTextResponse,
    ModelProvider,
} from "./llm.types";
import { anthropic } from "@ai-sdk/anthropic";
import { google } from "@ai-sdk/google";
import { openai } from "@ai-sdk/openai";
import {
    generateObject,
    generateText,
    type LanguageModel,
    type ToolSet,
} from "ai";
import type { AnyZodObject, z } from "zod";

export class LLM extends Base {
    private model: LanguageModel;

    constructor({ provider, id }: ModelProvider) {
        super("llm");
        switch (provider) {
            case "openai":
                this.model = openai(id);
                break;
            case "anthropic":
                this.model = anthropic(id);
                break;
            case "google":
                this.model = google(id);
                break;
        }
    }

    public async generate<ZOD_OBJECT extends AnyZodObject>(
        args: LLMParameters,
        viaAgent: boolean = false
    ): Promise<LLMResponse<ZOD_OBJECT>> {
        try {
            const hasTools =
                "tools" in args && Object.keys(args.tools ?? {}).length > 0;

            const isTextResponse = viaAgent || hasTools;

            if (isTextResponse) {
                const { tools, ...textArgs } = args as GenerateTextParams;
                const response = await generateText({
                    model: this.model,
                    toolChoice: "auto",
                    maxSteps: 3,
                    maxRetries: 5,
                    tools: tools as ToolSet,
                    ...textArgs,
                });

                if (!response.text) {
                    throw new Error(
                        "No response text generated by the model. Consider increasing `maxSteps` and/or `maxRetries`"
                    );
                }

                return {
                    type: "assistant",
                    value: response.text,
                } as LLMTextResponse;
            } else {
                const objectArgs = args as GenerateObjectParams;
                const response = await generateObject<z.infer<ZOD_OBJECT>>({
                    model: this.model,
                    maxRetries: 5,
                    output: "object",
                    ...objectArgs,
                });

                if (!response.object) {
                    throw new Error("No response object");
                }

                return {
                    type: "assistant",
                    value: response.object,
                } as LLMStructuredResponse<ZOD_OBJECT>;
            }
        } catch (error) {
            throw new Error(`Failed to parse response: ${error}`);
        }
    }
}
